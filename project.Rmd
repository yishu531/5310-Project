---
title: "5310 Power Project--T00728937 Yishu Liu"
author: "Yishu Liu"
date: "2024-04-16"
output: html_document
--- 

# 1.Testing power by t test and bootstrap on simulated data
## 1.1 Initial two data groups with normal distribution

### 1.1.1 Generate simulated data 
```{r}
# Set a random seed for reproducibility
set.seed(728937)

# Sample sizes
n11 <- 30 
n12 <- 30 

#set means
mean11_population <- 100
mean12_population <- 110

# set standard deviations 
sd11_population <- 15
sd12_population <- 15

# Generate two new sets of simulated sample data
simulated_data_group11 <- rnorm(n = n11, mean = mean11_population, sd = sd11_population)
simulated_data_group12 <- rnorm(n = n12, mean = mean12_population, sd = sd12_population)

# Display basic statistics for the data
summary(simulated_data_group11)
summary(simulated_data_group12)
```
### 1.1.2 Test the power 

#### T test 
```{r}
# Perform a two-sample t-test
t_test_result <- t.test(simulated_data_group11, simulated_data_group12)

# Print the results of the t-test
print(t_test_result)
```
The p value is smaller than 0.05, we can reject the H0 that the mean of these two groups are the same.

#### T test power
```{r}
# use sample statistics to calculate power

library(pwr)
# standard deviations of the two groups 
sd11 <- sd(simulated_data_group11)
sd12 <- sd(simulated_data_group12)

# Means of the two groups 
mean11 <- mean(simulated_data_group11)
mean12 <- mean(simulated_data_group12)

# Calculate the pooled standard deviation
sd_pooled1 <- sqrt(((n11 - 1)*sd11^2 + (n12 - 1)*sd12^2) / (n11 + n12 - 2))

# Calculate Cohen's d
d1 <- (mean12 - mean11) / sd_pooled1

# Conduct power analysis
power_analysis_1 <- pwr.t.test(d = d1, n = n11, sig.level = 0.05, type = "two.sample", alternative = "two.sided")

# Print the power analysis result
print(power_analysis_1)

```
The power using sample effect size is 0.67.

```{r}
#use population parameter to calculate power

# Calculate the pooled standard deviation
sd_pooled1_population <- sd11_population

# Calculate Cohen's d
d1_population <- (mean12_population - mean11_population) / sd_pooled1_population

# Conduct power analysis
power_analysis_1_population <- pwr.t.test(d = d1_population, n = n11, sig.level = 0.05, type = "two.sample", alternative = "two.sided")

# Print the power analysis result
print(power_analysis_1_population)
```
The power using real effect size is 0.71.

#### Bootstrap power
```{r}
# Define a function to perform bootstrap resampling and calculate mean differences
bootstrap_means_diff <- function(data1, data2, n_bootstrap) {
  boot_diffs <- numeric(n_bootstrap)
  for (i in 1:n_bootstrap) {
    sample1 <- sample(data1, replace = TRUE, size = length(data1))
    sample2 <- sample(data2, replace = TRUE, size = length(data2))
    boot_diffs[i] <- mean(sample1) - mean(sample2)
  }
  boot_diffs
}

# Initialize a counter for the number of times the confidence interval does not include zero
significant_count <- 0

# Set the number of simulations for power calculation
num_simulations <- 1000

# Run simulations to estimate the power
set.seed(5310) # Ensure reproducibility
for (i in 1:num_simulations) {
  # Generate two new sets of simulated data
  simulated_data_group13 <- rnorm(30, mean = 100, sd = 15)
  simulated_data_group14 <- rnorm(30, mean = 110, sd = 15)
  
  # Perform bootstrap resampling
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_group13, simulated_data_group14, 1000)
  
  # Estimate the 95% confidence interval for the mean difference
  CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
  
  # Check if the confidence interval does not include zero
  if (CI[1] > 0 || CI[2] < 0) {
    significant_count <- significant_count + 1
  }
}

# Calculate the power as the proportion of simulations where the effect was significant
bootstrap_power_1 <- significant_count / num_simulations

# Print the estimated power from the bootstrap simulations
print(bootstrap_power_1)

```
The power is 0.73, which is very close to the real power.

## 1.2 Two data groups - change on sample size

### T test power on several sample sizes
```{r}
# use initial population Cohen's d 
d2 <- d1_population

# significant level
alpha <- 0.05

# different sample sizes
sample_sizes_21 <- seq(from = 10, to = 100, by = 10)

# create the vector to save the power
powers_21 <- numeric(length(sample_sizes_21))

# calculate power with different sample sizes
for (i in seq_along(sample_sizes_21)) {
  powers_21[i] <- pwr.t.test(d = d2, n = sample_sizes_21[i], sig.level = alpha, type = "two.sample", alternative = "two.sided")$power
}

# check power
data.frame(Sample_Size = sample_sizes_21, Power = powers_21)
```

### Bootstrap power on several sample sizes
```{r}
# Create a vector of different sample sizes to test
sample_sizes_22 <- seq(from = 10, to = 100, by = 10)

# Initialize a vector to hold power calculations for each sample size
bootstrap_powers_2 <- numeric(length(sample_sizes_22))

# Set the number of simulations for power calculation
num_simulations <- 1000

# Set a reproducible seed
set.seed(5310)

# Loop over each sample size to calculate power
for (j in seq_along(sample_sizes_22)) {
  significant_count <- 0  # Initialize counter for significant results
  
  # Run simulations for current sample size
  for (i in 1:num_simulations) {
    # Generate two new sets of simulated data
    simulated_data_group21 <- rnorm(sample_sizes_22[j], mean = 100, sd = 15)
    simulated_data_group22 <- rnorm(sample_sizes_22[j], mean = 110, sd = 15)
    
    # Perform bootstrap resampling
    bootstrap_diffs <- bootstrap_means_diff(simulated_data_group21, simulated_data_group22, 1000) 
    
    
    # Estimate the 95% confidence interval for the mean difference
    CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
    
    # Check if the confidence interval does not include zero
    if (CI[1] > 0 || CI[2] < 0) {
      significant_count <- significant_count + 1
    }
  }
  
  # Calculate power for this sample size
  bootstrap_powers_2[j] <- significant_count / num_simulations
}

# print the sample sizes and their corresponding power estimates
data.frame(Sample_Size = sample_sizes_22, Power = bootstrap_powers_2)
```

### T test on two groups with different sample sizes
```{r}

# Set sample sizes for the two groups
n_group21 <- 30  
n_group22 <- 70  

# use the population effect size d2 (Cohen's d)
d2 <- d1_population

# Set the significance level (alpha)
alpha <- 0.05

# Calculate the power for unbalanced sample sizes using the pwr.t.test function
# The ratio is the size of group 2 divided by group 1
power_analysis_22 <- pwr.t2n.test(d = d2, n1 = n_group21, n2 = n_group22, sig.level = alpha, power = NULL, alternative = "two.sided")

# Print the results of the power analysis
print(power_analysis_22)
```

### Bootstrap on two groups with different sample sizes
```{r}
# Set sample sizes for the two groups
n_group23 <- 30  
n_group24 <- 70  

# Set the number of bootstrap resamples
n_bootstrap <- 1000

# Set the number of simulations for power calculation 
num_simulations <- 1000

# Initialize a counter for the number of times the confidence interval does not include zero
significant_count <- 0

# Set a reproducible seed
set.seed(5310)

# Run simulations to estimate the power
for (i in 1:num_simulations) {
  # Generate two new sets of simulated data with different sample sizes
  simulated_data_group23 <- rnorm(n_group23, mean = 100, sd = 15)
  simulated_data_group24 <- rnorm(n_group24, mean = 110, sd = 15)
  
  # Perform bootstrap resampling
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_group23, simulated_data_group24, n_bootstrap)
  
  # Estimate the 95% confidence interval for the mean difference
  CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
  
  # Check if the confidence interval does not include zero
  # Increment the count if the confidence interval excludes zero
  if (CI[1] > 0 || CI[2] < 0) {
    significant_count <- significant_count + 1
  }
}

# Calculate the power as the proportion of simulations where the effect was significant
bootstrap_power_22 <- significant_count / num_simulations

# Print the estimated power from the bootstrap simulations
print(bootstrap_power_22)
```


## 1.3 Two data groups - change on siginificant level

### T test power on several siginificant levels
```{r}
# We use Cohen's d based on population parameters: d1_population

# Different significance levels to test
significance_levels_3 <- c(0.01, 0.05, 0.10)

# Loop over each significance level to calculate power
for (alpha in significance_levels_3) {
  power_analysis_3 <- pwr.t.test(d = d1_population, n = 50, sig.level = alpha, type = "two.sample",
                               alternative = "two.sided")
  print(paste("Significance level:", alpha, "Power:", power_analysis_3$power))
}
```

### Bootstrap power on several siginificant levels
```{r}
# Set a seed for reproducibility
set.seed(5310)

# Loop over each significance level to estimate power
for (alpha in significance_levels_3) {
  significant_count <- 0
  for (i in 1:1000) {
  # Generate two new sets of simulated data
  simulated_data_group31 <- rnorm(50, mean = 100, sd = 15)
  simulated_data_group32 <- rnorm(50, mean = 110, sd = 15)
  
  # Perform bootstrap resampling
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_group31, simulated_data_group32, 1000)
  
    # Calculate the confidence interval bounds based on the current alpha
    CI <- quantile(bootstrap_diffs, probs = c(alpha/2, 1-alpha/2))
    
    # Check if the confidence interval does not include zero
    if (CI[1] > 0 || CI[2] < 0) {
      significant_count <- significant_count + 1
    }
  }
  
  # Calculate power
  bootstrap_power_3 <- significant_count / 1000
  print(paste("Significance level:", alpha, "Power:", bootstrap_power_3))
}

```


## 1.4 Two data groups - change on effect size
### T test power on several effect sizes
```{r}
# Different effect sizes to test
effect_sizes_4 <- seq(0.2, 1.0, by = 0.2)  # 0.2 small/0.5 middle/0.8 large

# Set the significance level
alpha <- 0.05

# Fixed sample size for both groups
n_4 <- 30

# Loop over each effect size to calculate power
for (d in effect_sizes_4) {
  power_analysis_4 <- pwr.t.test(n = n_4, d = d, sig.level = alpha, power = NULL,type = "two.sample",
                                 alternative = "two.sided")
  print(paste("Effect size:", d, "Power:", power_analysis_4$power))
}

```
### Bootstrap power on several effect sizes
```{r}
# Use the sample size n_4
# Use effect_sizes_4 to test

# Define the standard deviation for the population
pop_sd <- 15

# Set the number of bootstrap resamples and simulations
n_bootstrap <- 1000 
num_simulations <- 1000

# Loop over each effect size
for (d in effect_sizes_4) {
  significant_count <- 0
  
  # Run simulations for power estimation
  for (i in 1:num_simulations) {
    # Generate two new sets of simulated data
    simulated_data_group41 <- rnorm(n_4, mean = 100, sd = pop_sd)
    simulated_data_group42 <- rnorm(n_4, mean = 100 + d * pop_sd, sd = pop_sd)
    
    # Perform bootstrap resampling
    bootstrap_diffs <- bootstrap_means_diff(simulated_data_group41, simulated_data_group42, n_bootstrap)
    
    # Estimate the 95% confidence interval for the mean difference
    CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
    
    # If the confidence interval does not include zero, count it as significant
    if (CI[1] > 0 || CI[2] < 0) {
      significant_count <- significant_count + 1
    }
  }
  
  # Calculate and print the power
  bootstrap_power_4 <- significant_count / num_simulations
  print(paste("Effect size:", d, "Power:", bootstrap_power_4))
}

```


## 1.5 Two data groups - change on standard deviation
### T test power on several standard deviations
```{r}
# Set the sample size
n_5 <- 30 

# Different standard deviations to test
standard_deviations_5 <- seq(0, 50, by = 10)  

# Set the significance level and effect size
alpha <- 0.05
d5 <- 0.5  #example effect size

# Loop over each standard deviation to calculate power
for (sd in standard_deviations_5) {
  # Adjust the effect size for the new standard deviation
  adjusted_d5 <- (mean12_population - mean11_population) / sd  
  
  power_analysis_5 <- pwr.t.test(d = adjusted_d5, n = n_5, sig.level = alpha, 
                               type = "two.sample", alternative = "two.sided")
  print(paste("Standard deviation:", sd, "Adjusted effect size:", adjusted_d5, "Power:", power_analysis_5$power))
}
```

### Bootstrap power on several standard deviations
```{r} 

# Set a seed for reproducibility
set.seed(5310)

# Loop over each standard deviation to estimate power
for (sd in standard_deviations_5) {
  significant_count <- 0
  for (i in 1:1000) {
    # Generate two new sets of simulated data with the current standard deviation
    simulated_data_group51 <- rnorm(n_5, mean = mean11_population, sd = sd)
    simulated_data_group52 <- rnorm(n_5, mean = mean12_population, sd = sd)  
  
    # Perform bootstrap resampling
    bootstrap_diffs <- bootstrap_means_diff(simulated_data_group51, simulated_data_group52, 1000)
    
    # Estimate the 95% confidence interval for the mean difference
    CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
    
    # If the confidence interval does not include zero, count it as significant
    if (CI[1] > 0 || CI[2] < 0) {
      significant_count <- significant_count + 1
    }
  }
  
  # Calculate and print the power
  bootstrap_power_5 <- significant_count / 1000
  print(paste("Standard deviation:", sd, "Power:", bootstrap_power_5))
}

```


## 1.6 Two data groups - change on data distribution
### 1.6.1 Generate data in beta distribution
```{r}
set.seed(728937)
# Set the sample size and beta distribution parameters
size <- 30  # Sample size
alpha1 <- 2
beta1 <- 5
alpha2 <- 2
beta2 <- 6

# Generate two sets of beta distributed data
beta_data_group1 <- rbeta(size, alpha1, beta1)
beta_data_group2 <- rbeta(size, alpha2, beta2)


# calculate mean and different
mean61 <- mean(beta_data_group1)
mean62 <- mean(beta_data_group2)
sd61 <- sd(beta_data_group1)
sd62 <- sd(beta_data_group2)

# Linearly transform the data to the desired range [0, 100]
min_val <- 0
max_val <- 100
beta_data_group1 <- beta_data_group1 * (max_val - min_val) + min_val
beta_data_group2 <- beta_data_group2 * (max_val - min_val) + min_val

# Define a sequence of values between 0 and 1 to calculate the beta density
x <- seq(0, 1, length.out = 100)

# Calculate the beta density for the sequence of x values
y1 <- dbeta(x, alpha1, beta1)
y2 <- dbeta(x, alpha2, beta2)

# Plot the beta density for group 1
plot(x * (max_val - min_val) + min_val, y1, type='l', lwd=2, col='blue',
     main='Beta Distributions for Two Groups',
     xlab='Value', ylab='Density', ylim=c(0, max(c(y1, y2))))

# Add the beta density for group 2 to the plot
lines(x * (max_val - min_val) + min_val, y2, type='l', lwd=2, col='red')

# Add a legend to the plot
legend('topright', legend=c('Group 1', 'Group 2'), col=c('blue', 'red'), lty=1:1, cex=0.8)


print(paste("Mean of data group 1:", mean61))
print(paste("Mean of data group 2:", mean62))
```

### T test power with data in beta distribution
Actually we can not use t test in beta distribution, this power is not reliable.
```{r}
# calculate Cohen's d 
d6 <- (mean62 - mean61) / sqrt((sd61^2 + sd62^2) / 2)

#calculate power
power_analysis_6 <- pwr.t.test(d = d6, n = size, sig.level = 0.05, type = "two.sample", alternative = "two.sided")

# print result
print(power_analysis_6)
```

### Bootstrap power with data in beta distribution
```{r}
# Initialize a counter for the number of times the confidence interval does not include zero
significant_count <- 0

# Set the number of simulations for power calculation
num_simulations <- 1000

# Run simulations to estimate the power
set.seed(5310)  # Ensure reproducibility

for (i in 1:num_simulations) {
  # Generate two new sets of simulated beta distributed data
  simulated_data_beta1 <- rbeta(30, alpha1, beta1)
  simulated_data_beta2 <- rbeta(30, alpha2, beta2)

  # Perform bootstrap resampling
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_beta1, simulated_data_beta2, 1000)
  
  # Estimate the 95% confidence interval for the mean difference
  CI <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
  
  # Check if the confidence interval does not include zero
  if (CI[1] > 0 || CI[2] < 0) {
    significant_count <- significant_count + 1
  }
}

# Calculate the power as the proportion of simulations where the effect was significant
bootstrap_power <- significant_count / num_simulations

# Print the estimated power from the bootstrap simulations
print(bootstrap_power)

```





# 2.Testing power by t test and bootstrap on real data

## 2.1 Data Processing
### Height data of Canada and China-Normal Distribution
```{r}
# import the data
Canada_height <- read.csv("~/Downloads/Canada_height.csv")
China_height<- read.csv("~/Downloads/China_height.csv")

head(Canada_height)
head(China_height)
```

## 2.2 Power Test
### T test on boys' height at age 5 in 2011 between Canada and China
```{r}
# filter boys at age 5 in 2011
Canada_data_2011 <- Canada_height[Canada_height$Year == 2011 & Canada_height$Age_group == 5  & Canada_height$Sex == 'Boys', ]
China_data_2011 <- China_height[China_height$Year == 2011 & China_height$Age_group == 5 & China_height$Sex == 'Boys', ]

# mean and sd
Canada_boy_mean_2011 <- Canada_data_2011$Mean_height
Canada_boy_se_2011 <- Canada_data_2011$Mean_height_standard_error
China_boy_mean_2011 <- China_data_2011$Mean_height
China_boy_se_2011 <- China_data_2011$Mean_height_standard_error

# print
print(paste("Canada 2011 Mean Height:", Canada_boy_mean_2011, "SE:", Canada_boy_se_2011))
print(paste("China 2011 Mean Height:", China_boy_mean_2011, "SE:", China_boy_se_2011))

```

#### assume sample size is 20
```{r}
library(pwr)
# assume the sample size is 20
alpha <- 0.05
n <- 20  

Canada_boy_sd_2011_1 <- Canada_boy_se_2011 * sqrt(n)
China_boy_sd_2011_1 <- China_boy_se_2011 * sqrt(n)

# Calculate the pooled standard deviation
var_pooled_7 <- (Canada_boy_sd_2011_1^2 + China_boy_sd_2011_1^2)/2
sd_pooled_7 <- sqrt(var_pooled_7)

# Calculate Cohen's d
effect_size_7 <- (Canada_boy_mean_2011 - China_boy_mean_2011) / sd_pooled_7

set.seed(5310)
simulated_data_group71 <- rnorm(n = n, mean = Canada_boy_mean_2011, sd = Canada_boy_sd_2011_1)
simulated_data_group72 <- rnorm(n = n, mean = China_boy_mean_2011, sd = China_boy_sd_2011_1)

# Perform a two-sample t-test
t_test_result_7 <- t.test(simulated_data_group71, simulated_data_group72)

# Print the results of the t-test
print(t_test_result_7)

# calculate power
power_analysis_7 <- pwr.t.test(d = effect_size_7, n = n, sig.level = alpha, type = "two.sample", alternative = "two.sided")
print(power_analysis_7)

```

#### assume sample size is 200
```{r}
# assume the sample size is 00
alpha <- 0.05
n <- 200  

Canada_boy_sd_2011_2 <- Canada_boy_se_2011 * sqrt(n)
China_boy_sd_2011_2 <- China_boy_se_2011 * sqrt(n)

# Perform a two-sample t-test
set.seed(5310)
simulated_data_group71 <- rnorm(n = n, mean = Canada_boy_mean_2011, sd = Canada_boy_sd_2011_2)
simulated_data_group72 <- rnorm(n = n, mean = China_boy_mean_2011, sd = China_boy_sd_2011_2)
t_test_result_7 <- t.test(simulated_data_group71, simulated_data_group72)

# Print the results of the t-test
print(t_test_result_7)

# calculate power
power_analysis_7 <- pwr.t.test(d = effect_size_7, n = n, sig.level = alpha, type = "two.sample", alternative = "two.sided")
print(power_analysis_7)

```

### Bootstrap on boys'height at age 5 in 2011 between Canada and China
#### assume sample size is 20
```{r}
n <- 20 

num_simulations <- 1000  
significant_count <- 0

for(i in 1:num_simulations){
  
  # bootstrap resampling
  simulated_data_group73 <- rnorm(n = n, mean = Canada_boy_mean_2011, sd = Canada_boy_sd_2011_1)
  simulated_data_group74 <- rnorm(n = n, mean = China_boy_mean_2011, sd = China_boy_sd_2011_1)
  
  # calculate the mean difference
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_group73, simulated_data_group74, 1000)
  
  # calculate CI
  ci <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
  
  # check if the CI contains 0
  if(ci[1] > 0 | ci[2] < 0){
    significant_count <- significant_count + 1
  }
}

# calculate power
power_8 <- significant_count / num_simulations
print(power_8)

```


#### assume sample size is 200
```{r}
n <- 200 

num_simulations <- 1000  
significant_count <- 0

for(i in 1:num_simulations){
  
  # bootstrap resampling
  simulated_data_group73 <- rnorm(n = n, mean = Canada_boy_mean_2011, sd = Canada_boy_sd_2011_1)
  simulated_data_group74 <- rnorm(n = n, mean = China_boy_mean_2011, sd = China_boy_sd_2011_1)
  
  # calculate the mean difference
  bootstrap_diffs <- bootstrap_means_diff(simulated_data_group73, simulated_data_group74, 1000)
  
  # calculate CI
  ci <- quantile(bootstrap_diffs, probs = c(0.025, 0.975))
  
  # check if the CI contains 0
  if(ci[1] > 0 | ci[2] < 0){
    significant_count <- significant_count + 1
  }
}

# calculate power
power_8 <- significant_count / num_simulations
print(power_8)

```
